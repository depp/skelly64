{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Skelly 64 is a set of tools for creating assets for homebrew Nintendo 64 games. Warning This project is a work in progress. Skelly 64 is just not complete, or very usable yet. The tools were designed to be used in a game for the N64Brew Jam in 2020, and it will take time to document these tools, fix some bugs, and make them work for more general cases. While I\u2019d like to make these tools usable for your project, these tools aren\u2019t really ready yet! That\u2019s why I\u2019m creating these docs. I\u2019m looking forward to removing this section from the docs. Homebrew, or ROM Hack? Skelly 64 is only designed to help you create new homebrew games, it won\u2019t help you make ROM hacks, it won't help you modify existing games, and it won't help you use textures or models from old Nintendo 64 games. A homebrew game is a completely new game for the Nintendo 64, made long after the console was no longer supported. This means new code, new sound, new graphics. A ROM hack is a modification to an old Nintendo 64 game, like Super Mario 64 or Ocarina of Time. ROM hacks and homebrew games are just too different from each other. With homebrew games, you are free to design the game however you want, and Skelly 64 will help. However, if you are working on a ROM hack, you have to work with the existing formats used in old Nintendo 64 games. Skelly 64 does not support these formats, and support for these old formats will never be added. License The Skelly 64 project is licensed under the terms of the Mozilla Public License v2.0 .","title":"Introduction"},{"location":"#introduction","text":"Skelly 64 is a set of tools for creating assets for homebrew Nintendo 64 games. Warning This project is a work in progress. Skelly 64 is just not complete, or very usable yet. The tools were designed to be used in a game for the N64Brew Jam in 2020, and it will take time to document these tools, fix some bugs, and make them work for more general cases. While I\u2019d like to make these tools usable for your project, these tools aren\u2019t really ready yet! That\u2019s why I\u2019m creating these docs. I\u2019m looking forward to removing this section from the docs.","title":"Introduction"},{"location":"#homebrew-or-rom-hack","text":"Skelly 64 is only designed to help you create new homebrew games, it won\u2019t help you make ROM hacks, it won't help you modify existing games, and it won't help you use textures or models from old Nintendo 64 games. A homebrew game is a completely new game for the Nintendo 64, made long after the console was no longer supported. This means new code, new sound, new graphics. A ROM hack is a modification to an old Nintendo 64 game, like Super Mario 64 or Ocarina of Time. ROM hacks and homebrew games are just too different from each other. With homebrew games, you are free to design the game however you want, and Skelly 64 will help. However, if you are working on a ROM hack, you have to work with the existing formats used in old Nintendo 64 games. Skelly 64 does not support these formats, and support for these old formats will never be added.","title":"Homebrew, or ROM Hack?"},{"location":"#license","text":"The Skelly 64 project is licensed under the terms of the Mozilla Public License v2.0 .","title":"License"},{"location":"building/","text":"Building Skelly 64 is distributed as source code, you will need to compile the tools in order to use them. Prerequisites Bazel 4.1.0. Newer version should also work. Pkg-config , used to find Assimp. SoX , used to convert audio data. Assimp , used to import 3D models. Debian To install the prerequisites on Debian, run: sudo apt install build-essential sox libassimp-dev macOS (Homebrew) To install the prerequisites using Homebrew on macOS: brew install bazel pkg-config sox assimp Building and Running You can build one of the tools by running Bazel. The first time you build a tool with Bazel, it will download some additional prerequisites, so you will need an active internet connection. For example, to build the font tool: bazel build -c opt //tools/font The -c opt tells Bazel to use the \u201coptimized build\u201d compilation mode, which enables compiler optimizations. This is recommended if you are just using the tools and not modifying them. Bazel will rebuild if you change this flag. You can build and run a tool with Bazel\u2019s run command: bazel run -c opt //tools/font To pass arguments to a tool, add -- to the end of the command, and put the arguments there (otherwise, Bazel will intercept the arguments). For example, to pass the -help flag to the font tool: bazel run -c opt //tools/font -- -help","title":"Building"},{"location":"building/#building","text":"Skelly 64 is distributed as source code, you will need to compile the tools in order to use them.","title":"Building"},{"location":"building/#prerequisites","text":"Bazel 4.1.0. Newer version should also work. Pkg-config , used to find Assimp. SoX , used to convert audio data. Assimp , used to import 3D models.","title":"Prerequisites"},{"location":"building/#debian","text":"To install the prerequisites on Debian, run: sudo apt install build-essential sox libassimp-dev","title":"Debian"},{"location":"building/#macos-homebrew","text":"To install the prerequisites using Homebrew on macOS: brew install bazel pkg-config sox assimp","title":"macOS (Homebrew)"},{"location":"building/#building-and-running","text":"You can build one of the tools by running Bazel. The first time you build a tool with Bazel, it will download some additional prerequisites, so you will need an active internet connection. For example, to build the font tool: bazel build -c opt //tools/font The -c opt tells Bazel to use the \u201coptimized build\u201d compilation mode, which enables compiler optimizations. This is recommended if you are just using the tools and not modifying them. Bazel will rebuild if you change this flag. You can build and run a tool with Bazel\u2019s run command: bazel run -c opt //tools/font To pass arguments to a tool, add -- to the end of the command, and put the arguments there (otherwise, Bazel will intercept the arguments). For example, to pass the -help flag to the font tool: bazel run -c opt //tools/font -- -help","title":"Building and Running"},{"location":"image/","text":"Image Converter The image converter converts PNG images to a format which can be used by the Nintendo 64. Warning Missing documentation.","title":"Image Converter"},{"location":"image/#image-converter","text":"The image converter converts PNG images to a format which can be used by the Nintendo 64. Warning Missing documentation.","title":"Image Converter"},{"location":"model/","text":"Model Converter Warning Missing documentation. The model converter converts models from standard formats like FBX into formats suitable for the Nintendo 64 homebrew projects. The Bazel target is //tools/model . Running model -model <input> -output <output.model> Options -animate : Convert animations. -axes <axes> : Change the axes of the 3D model. This can be used to convert between left-handed and right-handed systems, or change which axis a model is facing towards. Defaults to x,y,z . (TODO: how does this work?) -meter <expr> : Define the length of a meter. The meter can be used by the -scale flag. The length can be a number or a simple numerical expression, such as -meter 100/64 . -model <input> : Use <input> as the input model. The input may be an FBX model. Other model formats may work, but are not tested. -output <output.model> : Write the model to <output.model> . The output is a custom format. -output-c <output.c> : Write the model as C source code to <output.c> . This may not work correctly and is not intended to be used in real games, but it shows the GBI commands used in the output model. -output-stats <output.log> : Write information about the model to <output.log> . This information is human-readable and should not be parsed. -scale <expr> : Scale the model by this factor. The factor can be a number or a numerical expression, and it can be defined in terms of the value for the -meter flag. For example, -scale 64/300 or -scale \"meter*10\" . -texcoord-bits <num> : Set the number of fractional bits of precision used for texture coordinates. Defaults to 11. -use-normals : Use vertex normals from model. Cannot be combined with vertex colors. -use-primitive-color : Use primitive color from material. (TODO: What part of the material?) -use-texcoords : Include texture coordinates. -use-vertex-colors : Include vertex colors. Cannot be combined with normals. -variable-name <name> : Use <name> as the name of the variable which contains the model data generated with -output-c . Building To build, bazel build -c opt //tools/model This will place the tool in bazel-bin/tools/model/model . Input Formats The converter supports the FBX format for input. Note The model converter uses the Open Asset Import Library , and in theory, can use other formats that the Open Asset Import Library supports. However, this is not tested. Note In the future, glTF may become the recommended format.","title":"Overview"},{"location":"model/#model-converter","text":"Warning Missing documentation. The model converter converts models from standard formats like FBX into formats suitable for the Nintendo 64 homebrew projects. The Bazel target is //tools/model .","title":"Model Converter"},{"location":"model/#running","text":"model -model <input> -output <output.model>","title":"Running"},{"location":"model/#options","text":"-animate : Convert animations. -axes <axes> : Change the axes of the 3D model. This can be used to convert between left-handed and right-handed systems, or change which axis a model is facing towards. Defaults to x,y,z . (TODO: how does this work?) -meter <expr> : Define the length of a meter. The meter can be used by the -scale flag. The length can be a number or a simple numerical expression, such as -meter 100/64 . -model <input> : Use <input> as the input model. The input may be an FBX model. Other model formats may work, but are not tested. -output <output.model> : Write the model to <output.model> . The output is a custom format. -output-c <output.c> : Write the model as C source code to <output.c> . This may not work correctly and is not intended to be used in real games, but it shows the GBI commands used in the output model. -output-stats <output.log> : Write information about the model to <output.log> . This information is human-readable and should not be parsed. -scale <expr> : Scale the model by this factor. The factor can be a number or a numerical expression, and it can be defined in terms of the value for the -meter flag. For example, -scale 64/300 or -scale \"meter*10\" . -texcoord-bits <num> : Set the number of fractional bits of precision used for texture coordinates. Defaults to 11. -use-normals : Use vertex normals from model. Cannot be combined with vertex colors. -use-primitive-color : Use primitive color from material. (TODO: What part of the material?) -use-texcoords : Include texture coordinates. -use-vertex-colors : Include vertex colors. Cannot be combined with normals. -variable-name <name> : Use <name> as the name of the variable which contains the model data generated with -output-c .","title":"Options"},{"location":"model/#building","text":"To build, bazel build -c opt //tools/model This will place the tool in bazel-bin/tools/model/model .","title":"Building"},{"location":"model/#input-formats","text":"The converter supports the FBX format for input. Note The model converter uses the Open Asset Import Library , and in theory, can use other formats that the Open Asset Import Library supports. However, this is not tested. Note In the future, glTF may become the recommended format.","title":"Input Formats"},{"location":"model_format/","text":"Model Format Warning This project is in-progress, and the format may change. The model format consists of three sections: Header Main data Vertex data All values are stored in big endian. Any pointers in C structures are serialized as offsets measured from the start of the same section. Header Offset Type Description 0 byte[16] Magic 16 uint32 Main data offset 20 uint32 Main data size 24 uint32 Vertex data offset 28 uint32 Vertex data size The \u201cmagic\u201d identifies this file type, and it consists of the ASCII string \u201cModel\u201d followed by null bytes. The remaining fields locate the other sections in the file. The remaining fields describe where the other sections are. Offsets are measured from the beginning of the file. Main Data The main data contains the display lists and various metadata like timing information. enum { MATERIAL_SLOTS = 4, }; struct model_header { Vtx *vertex_data; Gfx *display_list[MATERIAL_SLOTS]; int animation_count; unsigned frame_size; struct model_animation animation[]; }; Offset Type Description 0 uint32 Non-animated vertex data offset 4 uint32[4] Display list offset 20 uint32 Number of animations 24 uint32 Frame vertex data size 28 animdata[] Animation data The non-animated vertex data offset is the relative offset, from the start of the main data section, of the default vertex data. In the current tool, the vertex data is always present. It is not needed for animations, but used instead for non-animated models. The display list offsets are the relative offsets, from the start of the main data section, of the display lists for each material in the model. Four materials are supported per model. The display lists refer to vertex data through segment 1. It is assumed that segment 1 points to the beginning of the vertex data for the current animation frame. The animation count gives the size of the animation data array. The frame vertex data size is the size, in bytes, of the vertex data for a single frame. Animation Data The animation data array consists of items with this structure: struct model_animation { float duration; int frame_count; struct model_frame *frame; }; Offset Type Description 0 float32 Duration (seconds) 4 uint32 Frame count 8 uint32 Offset of first frame The offset of the first frame is measured from the beginning of the main data section. It contains an array of frame data. Frame Data The metadata for each frame is stored in frame data structures. struct model_frame { float time; float inv_dt; unsigned vertex; }; Offset Type Description 0 float32 Duration (seconds) 4 float32 Inverse of duration (1/seconds) 8 uint32 Vertex data offset The vertex data offset is relative to the start of the vertex data section. Vertex Data The vertex data consists of the vertex data for each frame of animation, an array of Vtx . A frame can be selected by mapping the vertex data for that frame into segment 1.","title":"Format"},{"location":"model_format/#model-format","text":"Warning This project is in-progress, and the format may change. The model format consists of three sections: Header Main data Vertex data All values are stored in big endian. Any pointers in C structures are serialized as offsets measured from the start of the same section.","title":"Model Format"},{"location":"model_format/#header","text":"Offset Type Description 0 byte[16] Magic 16 uint32 Main data offset 20 uint32 Main data size 24 uint32 Vertex data offset 28 uint32 Vertex data size The \u201cmagic\u201d identifies this file type, and it consists of the ASCII string \u201cModel\u201d followed by null bytes. The remaining fields locate the other sections in the file. The remaining fields describe where the other sections are. Offsets are measured from the beginning of the file.","title":"Header"},{"location":"model_format/#main-data","text":"The main data contains the display lists and various metadata like timing information. enum { MATERIAL_SLOTS = 4, }; struct model_header { Vtx *vertex_data; Gfx *display_list[MATERIAL_SLOTS]; int animation_count; unsigned frame_size; struct model_animation animation[]; }; Offset Type Description 0 uint32 Non-animated vertex data offset 4 uint32[4] Display list offset 20 uint32 Number of animations 24 uint32 Frame vertex data size 28 animdata[] Animation data The non-animated vertex data offset is the relative offset, from the start of the main data section, of the default vertex data. In the current tool, the vertex data is always present. It is not needed for animations, but used instead for non-animated models. The display list offsets are the relative offsets, from the start of the main data section, of the display lists for each material in the model. Four materials are supported per model. The display lists refer to vertex data through segment 1. It is assumed that segment 1 points to the beginning of the vertex data for the current animation frame. The animation count gives the size of the animation data array. The frame vertex data size is the size, in bytes, of the vertex data for a single frame.","title":"Main Data"},{"location":"model_format/#animation-data","text":"The animation data array consists of items with this structure: struct model_animation { float duration; int frame_count; struct model_frame *frame; }; Offset Type Description 0 float32 Duration (seconds) 4 uint32 Frame count 8 uint32 Offset of first frame The offset of the first frame is measured from the beginning of the main data section. It contains an array of frame data.","title":"Animation Data"},{"location":"model_format/#frame-data","text":"The metadata for each frame is stored in frame data structures. struct model_frame { float time; float inv_dt; unsigned vertex; }; Offset Type Description 0 float32 Duration (seconds) 4 float32 Inverse of duration (1/seconds) 8 uint32 Vertex data offset The vertex data offset is relative to the start of the vertex data section.","title":"Frame Data"},{"location":"model_format/#vertex-data","text":"The vertex data consists of the vertex data for each frame of animation, an array of Vtx . A frame can be selected by mapping the vertex data for that frame into segment 1.","title":"Vertex Data"},{"location":"rom/","text":"ROM Tool The ROM tool creates a Nintendo 64 ROM image from an ELF executable file. Warning Missing documentation.","title":"ROM Tool"},{"location":"rom/#rom-tool","text":"The ROM tool creates a Nintendo 64 ROM image from an ELF executable file. Warning Missing documentation.","title":"ROM Tool"},{"location":"font/","text":"Font Builder The font builder converts fonts to a format which can be used by the Nintendo 64. Features Supports most font formats. Uses the FreeType library, which supports common formats like TTF and OTF, as well as more obscure formats like BDF. Produces two types of fonts. \u201cTexture fonts\u201d are fonts designed to be loaded into texture memory (TMEM) on the RDP, and drawn by the RDP. \u201cFallback fonts\u201d are designed to be drawn by the CPU, for example, if you want to draw something on-screen from a crash handler. Includes only a subset of the glyphs in a font. You can choose which glyphs that you want, like A-Z, 0-9, and the punctuation you need. This reduces the amount of data you have to load into TMEM. Supports different character encodings. You can use Unicode, or a more convenient encoding like Windows-1252 or Latin-1. Adds shadows to the font, if desired. Running font -font <input> -font-size <size> [-out-data <output.font>] [<option>...] Font Options These options control how fonts are loaded, rendered to bitmaps, and transformed. -case <upper|lower> : Transform all text to upper-case or lower-case. -charset <file> : Only use a subset of the font, including characters from a character set file. -encoding <name> : Specify the character encoding. Only simple 8-bit character encodings are supported. By default, the glyphs are encoded as their Unicode code points. -font <input> : Read the font from <input> . Most font formats supported by the FreeType library should work. TrueType (TTF) has been tested and is known to work, as well as Adobe BDF. -font-size <size> : Render the font at <size> pixels. -mono : Render the font outline as monochrome (1-bit), with no antialiasing. -out-grid <file.png> : After loading the font and applying all transformations, arrange the glyphs in a grid and write it to <file.png> . -remove-notdef : Remove the .notdef glyph from the font, used for missing or undefined glyphs. When specified, missing or undefined glyphs will skipped, as if they were not present in the input. Otherwise, they will usually be rendered as little squares. -shadow <x>:<y>[:<alpha>] : Bake a drop shadow into the font texture. Increasing X values move the shadow farther right, and increasing Y values move the shadow farther down. Alpha should be between 0.0 and 1.0, and defaults to 1.0. Texture Font Output These options control how texture fonts are produced. Texture fonts are intended to be loaded into texture memory in the Nintendo 64\u2019s RDP, and rendered using RDP commands (either using RSP microcode, or by issuing RDP commands directly). -format <format> : Use <format> as the pixel format for the texture. This must be a texture format that the RDP supports (note: CI is not currently supported). -out-data <out.font> : Write the bitmap font out to a data file, using the Skelly 64 font file. -out-texture <out.png> : Combine the font\u2019s textures into a single PNG file, and write it out. Used for previewing what the glyphs look like, and seeing how they are packed. -texture-size <width>:<height> : Specify the size of each texture. Fallback Font Output -out-fallback <file.h> : Write the fallback font as C source code to <file.h> . Texture Formats The tool supports nine different texture formats, listed below: Bits RGBA CI IA I 32 rgba.32 16 rgba.16 ia.16 8 ci.8 ia.8 i.8 4 ci.4 ia.4 i.4 The format can be chosen with the -format option. Note that there is no meaningful way to use color index formats at the moment. Charset Note Missing documentation\u2014how to specify the charset.","title":"Overview"},{"location":"font/#font-builder","text":"The font builder converts fonts to a format which can be used by the Nintendo 64.","title":"Font Builder"},{"location":"font/#features","text":"Supports most font formats. Uses the FreeType library, which supports common formats like TTF and OTF, as well as more obscure formats like BDF. Produces two types of fonts. \u201cTexture fonts\u201d are fonts designed to be loaded into texture memory (TMEM) on the RDP, and drawn by the RDP. \u201cFallback fonts\u201d are designed to be drawn by the CPU, for example, if you want to draw something on-screen from a crash handler. Includes only a subset of the glyphs in a font. You can choose which glyphs that you want, like A-Z, 0-9, and the punctuation you need. This reduces the amount of data you have to load into TMEM. Supports different character encodings. You can use Unicode, or a more convenient encoding like Windows-1252 or Latin-1. Adds shadows to the font, if desired.","title":"Features"},{"location":"font/#running","text":"font -font <input> -font-size <size> [-out-data <output.font>] [<option>...]","title":"Running"},{"location":"font/#font-options","text":"These options control how fonts are loaded, rendered to bitmaps, and transformed. -case <upper|lower> : Transform all text to upper-case or lower-case. -charset <file> : Only use a subset of the font, including characters from a character set file. -encoding <name> : Specify the character encoding. Only simple 8-bit character encodings are supported. By default, the glyphs are encoded as their Unicode code points. -font <input> : Read the font from <input> . Most font formats supported by the FreeType library should work. TrueType (TTF) has been tested and is known to work, as well as Adobe BDF. -font-size <size> : Render the font at <size> pixels. -mono : Render the font outline as monochrome (1-bit), with no antialiasing. -out-grid <file.png> : After loading the font and applying all transformations, arrange the glyphs in a grid and write it to <file.png> . -remove-notdef : Remove the .notdef glyph from the font, used for missing or undefined glyphs. When specified, missing or undefined glyphs will skipped, as if they were not present in the input. Otherwise, they will usually be rendered as little squares. -shadow <x>:<y>[:<alpha>] : Bake a drop shadow into the font texture. Increasing X values move the shadow farther right, and increasing Y values move the shadow farther down. Alpha should be between 0.0 and 1.0, and defaults to 1.0.","title":"Font Options"},{"location":"font/#texture-font-output","text":"These options control how texture fonts are produced. Texture fonts are intended to be loaded into texture memory in the Nintendo 64\u2019s RDP, and rendered using RDP commands (either using RSP microcode, or by issuing RDP commands directly). -format <format> : Use <format> as the pixel format for the texture. This must be a texture format that the RDP supports (note: CI is not currently supported). -out-data <out.font> : Write the bitmap font out to a data file, using the Skelly 64 font file. -out-texture <out.png> : Combine the font\u2019s textures into a single PNG file, and write it out. Used for previewing what the glyphs look like, and seeing how they are packed. -texture-size <width>:<height> : Specify the size of each texture.","title":"Texture Font Output"},{"location":"font/#fallback-font-output","text":"-out-fallback <file.h> : Write the fallback font as C source code to <file.h> .","title":"Fallback Font Output"},{"location":"font/#texture-formats","text":"The tool supports nine different texture formats, listed below: Bits RGBA CI IA I 32 rgba.32 16 rgba.16 ia.16 8 ci.8 ia.8 i.8 4 ci.4 ia.4 i.4 The format can be chosen with the -format option. Note that there is no meaningful way to use color index formats at the moment.","title":"Texture Formats"},{"location":"font/#charset","text":"Note Missing documentation\u2014how to specify the charset.","title":"Charset"},{"location":"font/bitmap_example/","text":"Bitmap Example This is a subset of the Terminus font, rendered at size 12. The build scripts and data used to create this example are in the examples/font_bitmap folder. The font data takes only 1152 bytes in your ROM image, and doesn\u2019t require any additional RAM at runtime. This means that your debug logger or crash screen doesn\u2019t need to use up much of your precious memory. Note Missing documentation\u2014how was this created?","title":"Bitmap Example"},{"location":"font/bitmap_example/#bitmap-example","text":"This is a subset of the Terminus font, rendered at size 12. The build scripts and data used to create this example are in the examples/font_bitmap folder. The font data takes only 1152 bytes in your ROM image, and doesn\u2019t require any additional RAM at runtime. This means that your debug logger or crash screen doesn\u2019t need to use up much of your precious memory. Note Missing documentation\u2014how was this created?","title":"Bitmap Example"},{"location":"font/ttf_example/","text":"TTF Example This is a subset of the Alegreya Medium font, rendered at size 16. The build scripts and data used to create this example are in the examples/font_ttf folder. The packed textures Note Missing documentation\u2014how was this created?","title":"TTF Example"},{"location":"font/ttf_example/#ttf-example","text":"This is a subset of the Alegreya Medium font, rendered at size 16. The build scripts and data used to create this example are in the examples/font_ttf folder. The packed textures Note Missing documentation\u2014how was this created?","title":"TTF Example"},{"location":"vadpcm/","text":"VADPCM Audio Info The VADPCM audio converter is fully functional but the API and command-line interface are subject to change. VADPCM is a simple lossy audio compression codec used by Nintendo 64 games. VADPCM is one of two audio formats supported by the official Nintendo 64 SDK, and support for VADPCM is being added to LibDragon as well. Tools and Libraries The vadpcm tool encodes and decodes VADPCM audio from the command-line. To build it, bazel build -c opt //tools/vadpcm This will place the built executable at bazel-bin/tools/vadpcm/vadpcm . The encoding and decoding library is found in lib/vadpcm . Background In retail Nintendo 64 games, cartridge space was expensive, so VADPCM was primarily used for things like sound effects and musical instrument samples for MIDI playback. For homebrew games, cartridge space is much cheaper, and you can more easily justify using VADPCM to encode your entire soundtrack. At least one retail Nintendo 64 game is known to use VADPCM audio for its soundtrack: Star Wars, Shadows of the Empire . From an article in Game Developer, April 2009 , At this point, we tried an experiment using uncompressed digital samples of the Star Wars main theme. The quality was extremely good, even after subsequent compression with the ADPCM encoder provided by Nintendo. After a little persuasion, Nintendo generously agreed to increase the amount of cartridge space from 8MB to 12MB. This allowed us to include approximately 15 minutes of 16-bit, 11khz, mono music that sounded surprisingly good. Considering that most users would listen to the music through their televisions (rather than a sophisticated audio system), the results were close to that of an audio CD, thereby justifying the extra cartridge space required. Bit Rate Audio encoded in VADPCM uses exactly 4.5 bits per sample. The bit rate can only be changed by using a different sample rate. Here are some common sample rates, and the amount of data that VADPCM uses at each sample rate: Sample Rate Bit Rate Length per Megabyte 44.1 kHz 198 kbit/s 42.3 s/MiB 32 kHz 144 kbit/s 58.3 s/MiB 22.05 kHz 99.2 kbit/s 84.5 s/MiB 16 kHz 72.0 kbit/s 117 s/MiB 11.025 kHz 49.6 kbit/s 169 s/MiB","title":"Audio Overview"},{"location":"vadpcm/#vadpcm-audio","text":"Info The VADPCM audio converter is fully functional but the API and command-line interface are subject to change. VADPCM is a simple lossy audio compression codec used by Nintendo 64 games. VADPCM is one of two audio formats supported by the official Nintendo 64 SDK, and support for VADPCM is being added to LibDragon as well.","title":"VADPCM Audio"},{"location":"vadpcm/#tools-and-libraries","text":"The vadpcm tool encodes and decodes VADPCM audio from the command-line. To build it, bazel build -c opt //tools/vadpcm This will place the built executable at bazel-bin/tools/vadpcm/vadpcm . The encoding and decoding library is found in lib/vadpcm .","title":"Tools and Libraries"},{"location":"vadpcm/#background","text":"In retail Nintendo 64 games, cartridge space was expensive, so VADPCM was primarily used for things like sound effects and musical instrument samples for MIDI playback. For homebrew games, cartridge space is much cheaper, and you can more easily justify using VADPCM to encode your entire soundtrack. At least one retail Nintendo 64 game is known to use VADPCM audio for its soundtrack: Star Wars, Shadows of the Empire . From an article in Game Developer, April 2009 , At this point, we tried an experiment using uncompressed digital samples of the Star Wars main theme. The quality was extremely good, even after subsequent compression with the ADPCM encoder provided by Nintendo. After a little persuasion, Nintendo generously agreed to increase the amount of cartridge space from 8MB to 12MB. This allowed us to include approximately 15 minutes of 16-bit, 11khz, mono music that sounded surprisingly good. Considering that most users would listen to the music through their televisions (rather than a sophisticated audio system), the results were close to that of an audio CD, thereby justifying the extra cartridge space required.","title":"Background"},{"location":"vadpcm/#bit-rate","text":"Audio encoded in VADPCM uses exactly 4.5 bits per sample. The bit rate can only be changed by using a different sample rate. Here are some common sample rates, and the amount of data that VADPCM uses at each sample rate: Sample Rate Bit Rate Length per Megabyte 44.1 kHz 198 kbit/s 42.3 s/MiB 32 kHz 144 kbit/s 58.3 s/MiB 22.05 kHz 99.2 kbit/s 84.5 s/MiB 16 kHz 72.0 kbit/s 117 s/MiB 11.025 kHz 49.6 kbit/s 169 s/MiB","title":"Bit Rate"},{"location":"vadpcm/codec/","text":"VADPCM Codec This page describes the VADPCM codec in detail. With this information, you should be able to write your own VADPCM decoder. Writing an encoder is more difficult. Theory of Operation VADPCM uses linear predictors to predict what each sample of audio will be, based on the previous samples. The residual difference between the predicted value and the actual value is quantized to 4 bits. Each encoded frame of audio contains 16 samples with the same predictor coefficients and residual quantization. In theory, you decode a sample in two steps: Predict the sample value from a linear combination of previous output samples. Add the residual value to the predicted value. The actual decoding process is different, and is easy to vectorize using SIMD operations\u2014this may be where the \u201cV\u201d in \u201cVADPCM\u201d comes from. Encoded Data VADPCM audio consists of two parts: the codebook (which contains predictors) and the audio data . Codebook The codebook contains the parameters necessary for decoding the associated audio data. A codebook has a predictor order, a predictor count, and an array of predictor vectors. Predictor Order The predictor order can theoretically be any number from 0 to 8, but in practice, it is always 2. This value is the order of the linear predictors in the codebook. The predictor order is limited by the size of the array used to track decoder state in the decoder, which is 8. Predictor Count The predictor count is just the number of predictors in the codebook. This can be any number from 1 to 16. It is limited by the number of bits used to encode predictors in the encoded audio data. Predictor Vectors The predictor vectors are vectors of 8 signed 16-bit numbers. These are pre-calculated values derived during the encoding process. The number of vectors is equal to the predictor order, multiplied by the number of predictors. Audio Data The audio data is packed into frames. Each frame is 8 bytes and contains 9 samples of audio data, giving exactly 4.5 bits per sample. A frame contains a scaling factor, a predictor index, and residual audio data. Scaling Factor The scaling factor is a number in the range 0-12. This is used to scale the residual audio data. During decoding, the residual audio data is shifted left by the scaling factor. Values larger than 12 would result in overflow when shifting. Predictor Index The predictor index is a number 0-15, which is a reference to a set of predictor vectors in the codebook. The predictor vectors are used to predict the value of future audio samples from the previous output. Residual Audio Data The residual audio data is an array of 16 four-bit numbers. This contains the difference between the predicted sample data and the actual sample data, scaled down by the scaling factor. Decoding Process Decoding is done in vectors of 8 samples each. Each frame contains two vectors with a shared scaling factor and predictor index. Correctly decoding a frame requires the previous frame\u2019s decoded output, which serves as the decoder state. The initial state is all zeroes. The process for decoding a vector is as follows: Initialize an accumulator to all zeroes. For a predictor order of K, multiply each of the K predictor vectors by the corresponding last K output samples, and add them to the accumulator. For each index in the output vector I = 1..8, Calculate the predicted output sample by shifting the corresponding element in the accumulator to the right by 11 bits. Scale the residual value by shifting it left by the frame\u2019s scaling factor. Add the scaled residual value and the predicted output sample. This is the output sample. Shift the Kth predictor vector to the right by I elements, multiply this vector by the scaled residual value, and add this vector to the accumulator. In C, you can decode a vector of VADPCM like this: void decode(int predictor_order, int scaling_factor, int predictor[predictor_order][8], int state[8], int residual[8], int output[8]) { // Zero the accumulator. int accumulator[8]; for (int i = 0; i < 8; i++) { accumulator[i] = 0; } // Add previous output to accumulator. for (int i = 0; i < predictor_order; i++) { int previous_output = state[8 - predictor_order + i]; for (int j = 0; j < 8; j++) { accumulator[j] += predictor[i][j] * previous_output; } } // Calculate each output sample, and update the accumulator. for (int i = 0; i < 8; i++) { int scaled_residual = residual[i] << scaling_factor; output[i] = (accumulator[i] >> 11) + scaled_residual; for (int j = 0; j < 7 - i; j++) { accumulator[i + 1 + j] += predictor[predictor_order - 1][j] * scaled_residual; } } // New decoder state is equal to the output. for (int i = 0; i < 8; i++) { state[i] = output[i]; } } Encoding Process The Skelly 64 VADPCM encoder uses the following process to encode VADPCM: Break the input into frames of 16 samples each. For each frame, calculate a 3x3 autocorrelation matrix. Using a clustering algorithm, assign each frame to predictors. This algorithm searches for assignments that minimize the residual. The residual can be calculated from the autocorrelation matrix and the predictor coefficients, and the optimum predictor coefficients can be calculated from the autocorrelation matrix. Calculate the predictor vectors from the optimum predictor coefficients for each predictor. This results in a codebook. With the codebook and predictor assignments, encode each frame as VADPCM. Wire Format Only AIFC files have a known way to carry VADPCM data. However, the codec is not explicitly tied to AIFC and could easily be adapted to other formats. Predictor Vectors Each predictor is stored, one after the other. For example, if there are N predictors and the predictor order is K, the predictor vectors will have the following format: Type Description int16[8] Predictor 1, vector 1 int16[8] Predictor 1, vector 2 \u2026 \u2026 int16[8] Predictor 1, vector K int16[8] Predictor 2, vector 1 int16[8] Predictor 2, vector 2 \u2026 \u2026 int16[8] Predictor N, vector K Common Chunk (AIFC) The 'COMM' chunk for VADPCM-encoded AIFC files uses a sample size of 16 bits. The encoding type is 'VAPC' , and the encoding name is \"VADPCM ~4-1\" . Codebook (AIFC) The VADPCMCODES application-specific chunk in an AIFC file contains the codebook. The chunk, including its header, has the following format: Offset Type Description 0 uint32 Chunk ID, 'APPL' 4 uint32 Chunk size, starting after this field 8 uint32 Application signature, 'stoc' 12 uint8 Length of chunk name, 11 13 char[11] Chunk name, \"VADPCMCODES\" 24 uint16 VADPCM codec version, 1 26 uint16 Predictor order, 0-8 28 uint16 Predictor count, 1-16 30 int16[] Predictor vectors Audio Data A frame of audio data is stored as 9 bytes. Offset Type Description 0 uint8 Control byte 1 uint8[8] Residual The control byte stores the scaling factor as the high four bits, and the predictor index in the low four bits. Each byte in the residual encodes a pair of two successive residual audio values, stored as signed four-bit numbers. The first sample in each pair is stored in the high four bits and the second sample is stored in the low four bits.","title":"VADPCM Codec"},{"location":"vadpcm/codec/#vadpcm-codec","text":"This page describes the VADPCM codec in detail. With this information, you should be able to write your own VADPCM decoder. Writing an encoder is more difficult.","title":"VADPCM Codec"},{"location":"vadpcm/codec/#theory-of-operation","text":"VADPCM uses linear predictors to predict what each sample of audio will be, based on the previous samples. The residual difference between the predicted value and the actual value is quantized to 4 bits. Each encoded frame of audio contains 16 samples with the same predictor coefficients and residual quantization. In theory, you decode a sample in two steps: Predict the sample value from a linear combination of previous output samples. Add the residual value to the predicted value. The actual decoding process is different, and is easy to vectorize using SIMD operations\u2014this may be where the \u201cV\u201d in \u201cVADPCM\u201d comes from.","title":"Theory of Operation"},{"location":"vadpcm/codec/#encoded-data","text":"VADPCM audio consists of two parts: the codebook (which contains predictors) and the audio data .","title":"Encoded Data"},{"location":"vadpcm/codec/#codebook","text":"The codebook contains the parameters necessary for decoding the associated audio data. A codebook has a predictor order, a predictor count, and an array of predictor vectors. Predictor Order The predictor order can theoretically be any number from 0 to 8, but in practice, it is always 2. This value is the order of the linear predictors in the codebook. The predictor order is limited by the size of the array used to track decoder state in the decoder, which is 8. Predictor Count The predictor count is just the number of predictors in the codebook. This can be any number from 1 to 16. It is limited by the number of bits used to encode predictors in the encoded audio data. Predictor Vectors The predictor vectors are vectors of 8 signed 16-bit numbers. These are pre-calculated values derived during the encoding process. The number of vectors is equal to the predictor order, multiplied by the number of predictors.","title":"Codebook"},{"location":"vadpcm/codec/#audio-data","text":"The audio data is packed into frames. Each frame is 8 bytes and contains 9 samples of audio data, giving exactly 4.5 bits per sample. A frame contains a scaling factor, a predictor index, and residual audio data. Scaling Factor The scaling factor is a number in the range 0-12. This is used to scale the residual audio data. During decoding, the residual audio data is shifted left by the scaling factor. Values larger than 12 would result in overflow when shifting. Predictor Index The predictor index is a number 0-15, which is a reference to a set of predictor vectors in the codebook. The predictor vectors are used to predict the value of future audio samples from the previous output. Residual Audio Data The residual audio data is an array of 16 four-bit numbers. This contains the difference between the predicted sample data and the actual sample data, scaled down by the scaling factor.","title":"Audio Data"},{"location":"vadpcm/codec/#decoding-process","text":"Decoding is done in vectors of 8 samples each. Each frame contains two vectors with a shared scaling factor and predictor index. Correctly decoding a frame requires the previous frame\u2019s decoded output, which serves as the decoder state. The initial state is all zeroes. The process for decoding a vector is as follows: Initialize an accumulator to all zeroes. For a predictor order of K, multiply each of the K predictor vectors by the corresponding last K output samples, and add them to the accumulator. For each index in the output vector I = 1..8, Calculate the predicted output sample by shifting the corresponding element in the accumulator to the right by 11 bits. Scale the residual value by shifting it left by the frame\u2019s scaling factor. Add the scaled residual value and the predicted output sample. This is the output sample. Shift the Kth predictor vector to the right by I elements, multiply this vector by the scaled residual value, and add this vector to the accumulator. In C, you can decode a vector of VADPCM like this: void decode(int predictor_order, int scaling_factor, int predictor[predictor_order][8], int state[8], int residual[8], int output[8]) { // Zero the accumulator. int accumulator[8]; for (int i = 0; i < 8; i++) { accumulator[i] = 0; } // Add previous output to accumulator. for (int i = 0; i < predictor_order; i++) { int previous_output = state[8 - predictor_order + i]; for (int j = 0; j < 8; j++) { accumulator[j] += predictor[i][j] * previous_output; } } // Calculate each output sample, and update the accumulator. for (int i = 0; i < 8; i++) { int scaled_residual = residual[i] << scaling_factor; output[i] = (accumulator[i] >> 11) + scaled_residual; for (int j = 0; j < 7 - i; j++) { accumulator[i + 1 + j] += predictor[predictor_order - 1][j] * scaled_residual; } } // New decoder state is equal to the output. for (int i = 0; i < 8; i++) { state[i] = output[i]; } }","title":"Decoding Process"},{"location":"vadpcm/codec/#encoding-process","text":"The Skelly 64 VADPCM encoder uses the following process to encode VADPCM: Break the input into frames of 16 samples each. For each frame, calculate a 3x3 autocorrelation matrix. Using a clustering algorithm, assign each frame to predictors. This algorithm searches for assignments that minimize the residual. The residual can be calculated from the autocorrelation matrix and the predictor coefficients, and the optimum predictor coefficients can be calculated from the autocorrelation matrix. Calculate the predictor vectors from the optimum predictor coefficients for each predictor. This results in a codebook. With the codebook and predictor assignments, encode each frame as VADPCM.","title":"Encoding Process"},{"location":"vadpcm/codec/#wire-format","text":"Only AIFC files have a known way to carry VADPCM data. However, the codec is not explicitly tied to AIFC and could easily be adapted to other formats.","title":"Wire Format"},{"location":"vadpcm/codec/#predictor-vectors","text":"Each predictor is stored, one after the other. For example, if there are N predictors and the predictor order is K, the predictor vectors will have the following format: Type Description int16[8] Predictor 1, vector 1 int16[8] Predictor 1, vector 2 \u2026 \u2026 int16[8] Predictor 1, vector K int16[8] Predictor 2, vector 1 int16[8] Predictor 2, vector 2 \u2026 \u2026 int16[8] Predictor N, vector K","title":"Predictor Vectors"},{"location":"vadpcm/codec/#common-chunk-aifc","text":"The 'COMM' chunk for VADPCM-encoded AIFC files uses a sample size of 16 bits. The encoding type is 'VAPC' , and the encoding name is \"VADPCM ~4-1\" .","title":"Common Chunk (AIFC)"},{"location":"vadpcm/codec/#codebook-aifc","text":"The VADPCMCODES application-specific chunk in an AIFC file contains the codebook. The chunk, including its header, has the following format: Offset Type Description 0 uint32 Chunk ID, 'APPL' 4 uint32 Chunk size, starting after this field 8 uint32 Application signature, 'stoc' 12 uint8 Length of chunk name, 11 13 char[11] Chunk name, \"VADPCMCODES\" 24 uint16 VADPCM codec version, 1 26 uint16 Predictor order, 0-8 28 uint16 Predictor count, 1-16 30 int16[] Predictor vectors","title":"Codebook (AIFC)"},{"location":"vadpcm/codec/#audio-data_1","text":"A frame of audio data is stored as 9 bytes. Offset Type Description 0 uint8 Control byte 1 uint8[8] Residual The control byte stores the scaling factor as the high four bits, and the predictor index in the low four bits. Each byte in the residual encodes a pair of two successive residual audio values, stored as signed four-bit numbers. The first sample in each pair is stored in the high four bits and the second sample is stored in the low four bits.","title":"Audio Data"},{"location":"vadpcm/decode/","text":"Decode VADPCM Usage: vadpcm decode <input.aifc> <output> Description Decodes an AIFC file that contains VADPCM audio. Produces an AIFF or AIFC file. Options This command takes no options.","title":"Decode VADPCM"},{"location":"vadpcm/decode/#decode-vadpcm","text":"Usage: vadpcm decode <input.aifc> <output>","title":"Decode VADPCM"},{"location":"vadpcm/decode/#description","text":"Decodes an AIFC file that contains VADPCM audio. Produces an AIFF or AIFC file.","title":"Description"},{"location":"vadpcm/decode/#options","text":"This command takes no options.","title":"Options"},{"location":"vadpcm/encode/","text":"Encode VADPCM Usage: vadpcm encode [-predictors=<N>] <input> <output.aifc> Description Encodes an audio file as VADPCM. The input audio must be a 16-bit monophonic AIFF file. Options -predictors=<N> The VADPCM codec uses a codebook containing 1-16 predictors. This option sets the number of predictors to N. Using more predictors may improve the audio quality somewhat. The default number of predictors is 4, and each predictor takes up 32 bytes of space in the codebook. -show-stats After encoding, compare the encoded audio to the original audio and calculate the amount of noise introduced by the encoder. Prints out the signal level, noise level, and signal-to-noise ratio in dB. -stats-out=<file.json> After encoding, compare the encoded audio to the original audio and write the signal level and noise level to a JSON file. The JSON file will represent an object with the following keys: signalLevel - The RMS level of the original audio, a number in the range 0.0-1.0. noiseLevel - The RMS level of the noise introduced by the encoder, a number in the range 0.0-1.0.","title":"Encode VADPCM"},{"location":"vadpcm/encode/#encode-vadpcm","text":"Usage: vadpcm encode [-predictors=<N>] <input> <output.aifc>","title":"Encode VADPCM"},{"location":"vadpcm/encode/#description","text":"Encodes an audio file as VADPCM. The input audio must be a 16-bit monophonic AIFF file.","title":"Description"},{"location":"vadpcm/encode/#options","text":"-predictors=<N> The VADPCM codec uses a codebook containing 1-16 predictors. This option sets the number of predictors to N. Using more predictors may improve the audio quality somewhat. The default number of predictors is 4, and each predictor takes up 32 bytes of space in the codebook. -show-stats After encoding, compare the encoded audio to the original audio and calculate the amount of noise introduced by the encoder. Prints out the signal level, noise level, and signal-to-noise ratio in dB. -stats-out=<file.json> After encoding, compare the encoded audio to the original audio and write the signal level and noise level to a JSON file. The JSON file will represent an object with the following keys: signalLevel - The RMS level of the original audio, a number in the range 0.0-1.0. noiseLevel - The RMS level of the noise introduced by the encoder, a number in the range 0.0-1.0.","title":"Options"}]}